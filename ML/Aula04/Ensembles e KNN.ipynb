{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ensembles e KNN.ipynb","provenance":[{"file_id":"10H6mfCb_fIVO9_IrpiI_ktBGaGYILzl_","timestamp":1587604260917}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"art5PFADYAxu","colab_type":"text"},"source":["# Exercício\n","## Ensembles e K-nearest neighbors\n","### Alunos (Nome e número usp):\n"," - Lucas Henrique Mantovani Jacintho - 10258942\n"," - Victor Luiz Fortes Rivelo - 9762960\n"," - Vinicius Henrique Borges - 9771546\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aFbyaeLeBAEf"},"source":["Para esse exercício, vamos utilizar novamente o dataset [Breast Cancer Winsconsin](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset)."]},{"cell_type":"markdown","metadata":{"id":"4-MKSaenTIO9","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 1.\n","\n","Carregue o dataset Breast Cancer do módulo `sklearn.datasets` e normalize os dados."]},{"cell_type":"code","metadata":{"id":"BlWsvQIvWsJt","colab_type":"code","colab":{}},"source":["from sklearn.datasets import load_breast_cancer\n","\n","X, y = load_breast_cancer(return_X_y=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW3ryWwBLsuF","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import scale\n","\n","X = scale(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"37u00oF9wviW","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 2.\n","\n","Aqui definiremos funções que serão utilizadas para simplificar as operações que faremos posteriormente. Dessa forma, implemente as funções abaixo:\n","\n","*   A função `get_mean_accuracy(model, X, y)` recebe um modelo `model` e um conjunto de atributos `X` e labels `y`. Ela deve calcular a acurácia do modelo utilizando 10-fold cross-validation estratificado e retornar a acurácia média dos 10 folds\n","*   A função `evaluate_models(models, X, y)` recebe um conjunto de modelos definidos por um dicionário e exibe, para cada modelo, seu nome seguido da sua acurácia (calculada com a função `get_mean_accuracy`). Um exemplo de saída para o dicionário `exemplo` abaixo seria:\n","> A acurácia do modelo \"Knn (n_neighbors = 5)\" é 85.00%\n",">\n","> A acurácia do modelo \"DT (gini)\" é 80.00%\n","\n","*   Finalmente, implemente a função `create_name_list(models)`. Essa função deve receber um dicionário e retornar uma lista contendo, para cada elemento do dicionário, uma tupla (chave, valor). Para o dicionário `exemplo`, essa função retornaria:\n","> `[ ('Knn (n_neighbors = 5)', KNeighborsClassifier(n_neighbors=5)), ('DT (gini)', DecisionTreeClassifier(criterion=\"gini\"))]`\n","\n","\n","```\n","exemplo = {\n","    'Knn (n_neighbors = 5)': KNeighborsClassifier(n_neighbors=5),\n","    'DT (gini)': DecisionTreeClassifier(criterion=\"gini\"),\n","}\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"8eSOrXmJy4oH","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import StratifiedKFold\n","import numpy as np\n","\n","def get_mean_accuracy(model, X, y):\n","  accuracies = []\n","  skf = StratifiedKFold(n_splits=10)\n","\n","  for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    model.fit(X_train, y_train)\n","    score = model.score(X_test, y_test)\n","\n","    accuracies.append(score)\n","\n","  return np.mean(accuracies)\n","\n","def evaluate_models(models, X, y):\n","  for experiment, model in models.items():\n","    print('A acurácia do modelo \"{}\" é {:.2f}%'.format(experiment, get_mean_accuracy(model, X, y) * 100))\n","\n","def create_name_list(models):\n","  return list(models.items())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOITu6JQ3j1J","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 3.\n","\n","Defina modelos de SVM (`sklearn.svm.SVC`) e MLP (`sklearn.neural_network.MLPClassifier`) para servir de *baseline* de comparação para modelos futuros. Para isso, teste ao menos 3 configurações de SVM e 3 configurações de MLP. Sua baseline será a melhor acurácia (utilizando 10-fold cross-validation estratificado) entre essas configurações. Utilize as funções definidas na Questão 2 quando necessário."]},{"cell_type":"code","metadata":{"id":"zyPWdrhERSXJ","colab_type":"code","colab":{}},"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HxaBVuUP6bqe","colab_type":"code","colab":{}},"source":["mlps = {\n","    \"MLP camada escondida (5, 5)\": MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=5000, random_state=42),\n","    \"MLP camada escondida (100,)\": MLPClassifier(max_iter=5000, random_state=42),\n","    \"MLP camada escondida (200,)\": MLPClassifier(hidden_layer_sizes=(200), max_iter=5000, random_state=42),\n","}\n","\n","svms = {\n","    \"SVM poly(3)\": SVC(kernel='poly', degree=3, random_state=42),\n","    \"SVM linear\": SVC(kernel='linear', random_state=42),\n","    \"SVM rbf\": SVC(random_state=42)\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A5NQ4hIgRQp6","colab_type":"code","outputId":"3f338197-6e7d-4c47-b10a-66afaee76b7d","executionInfo":{"status":"ok","timestamp":1587685997045,"user_tz":180,"elapsed":31303,"user":{"displayName":"Lucas Mantovani","photoUrl":"","userId":"08866136206092519187"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["print(\"MLPs\")\n","evaluate_models(mlps, X, y)\n","print()\n","print(\"SVMs\")\n","evaluate_models(svms, X, y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["MLPs\n","A acurácia do modelo \"MLP camada escondida (5, 5)\" é 97.89%\n","A acurácia do modelo \"MLP camada escondida (100,)\" é 97.37%\n","A acurácia do modelo \"MLP camada escondida (200,)\" é 97.89%\n","\n","SVMs\n","A acurácia do modelo \"SVM poly(3)\" é 90.34%\n","A acurácia do modelo \"SVM linear\" é 97.54%\n","A acurácia do modelo \"SVM rbf\" é 97.71%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jP8nyb4W4XyL","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 4.\n","\n","Agora defina dois dicionários de classificadores. Um dicionário deve conter apenas classificadores KNN (`sklearn.neighbors.KNeighborsClassifier`), enquanto o outro deve conter apenas classificadores DT (`sklearn.tree.DecisionTreeClassifier`). Crie ao menos 3 configurações diferentes para cada tipo de classificador. Depois calcule e exiba a acurácia de cada configuração criada utilizando 10-fold cross-validation estratificado."]},{"cell_type":"code","metadata":{"id":"G68fAKm6TpkZ","colab_type":"code","colab":{}},"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5x_mhGP6cVc","colab_type":"code","colab":{}},"source":["knns = {\n","  \"KNN (K=5)\": KNeighborsClassifier(),\n","  \"KNN (K=2)\": KNeighborsClassifier(n_neighbors=2),\n","  \"KNN (K=10)\": KNeighborsClassifier(n_neighbors=10),\n","}\n","\n","dts = {\n","  \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n","  \"Decision Tree w/ random split\": DecisionTreeClassifier(splitter='random', random_state=42),\n","  \"Decision Tree w/ max_depth = 3\": DecisionTreeClassifier(max_depth=3, random_state=42),\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lk3JUbSja-r4","colab_type":"code","outputId":"72230ed8-ed25-4ba0-d034-5d03c8046bbc","executionInfo":{"status":"ok","timestamp":1587685998571,"user_tz":180,"elapsed":1508,"user":{"displayName":"Lucas Mantovani","photoUrl":"","userId":"08866136206092519187"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["print(\"KNNs\")\n","evaluate_models(knns, X, y)\n","print()\n","print(\"DTs\")\n","evaluate_models(dts, X, y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["KNNs\n","A acurácia do modelo \"KNN (K=5)\" é 96.66%\n","A acurácia do modelo \"KNN (K=2)\" é 94.55%\n","A acurácia do modelo \"KNN (K=10)\" é 97.01%\n","\n","DTs\n","A acurácia do modelo \"Decision Tree\" é 92.80%\n","A acurácia do modelo \"Decision Tree w/ random split\" é 92.97%\n","A acurácia do modelo \"Decision Tree w/ max_depth = 3\" é 90.70%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WPXfbaMM6dcP","colab_type":"text"},"source":["\n","\n","---\n","\n","### Questão 5.\n","\n","Agora você deve definir um dicionário contendo diferentes configurações de ensembles a serem testados. Utilize as classes `StackingClassifier`, `AdaBoostClassifier` e `VotingClassifier` do módulo `sklearn.ensemble` (fique a vontade para escolher outros tipos de ensembles desse mesmo módulo). Crie pelo menos 5 configurações diferentes tomando como estimadores os modelos definidos na Questão 4. Calcule a acurácia de cada configuração de ensemble. \n","\n","Obs.: Lembre-se de utilizar as funções definidas anteriormente"]},{"cell_type":"code","metadata":{"id":"fVvqvLOi6M9Z","colab_type":"code","colab":{}},"source":["from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, StackingClassifier, VotingClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kZms-RshWb63","colab_type":"code","outputId":"64f900b3-1d3f-40a9-de44-d824a7242f65","executionInfo":{"status":"ok","timestamp":1587686578555,"user_tz":180,"elapsed":14890,"user":{"displayName":"Lucas Mantovani","photoUrl":"","userId":"08866136206092519187"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["print(\"KNNs\")\n","estimators = create_name_list(knns)\n","ensembles = {\n","  \"Stacking\": StackingClassifier(estimators),\n","  \"Voting\": VotingClassifier(estimators)\n","}\n","evaluate_models(ensembles, X, y)\n","\n","print()\n","\n","print(\"DTs\")\n","estimators = create_name_list(dts)\n","for name, estimator in estimators:\n","  ensembles = {\n","      \"Ada Boost {}\".format(name): AdaBoostClassifier(estimator),\n","      \"Bagging {}\".format(name): BaggingClassifier(estimator),\n","  }\n","  evaluate_models(ensembles, X, y)\n","\n","ensembles = {\n","  \"Extra Trees\": ExtraTreesClassifier(),\n","  \"Gradient Boosting\": GradientBoostingClassifier(),\n","  \"Random Forest\": RandomForestClassifier(),\n","  \"Stacking\": StackingClassifier(estimators),\n","  \"Voting\": VotingClassifier(estimators)\n","}\n","evaluate_models(ensembles, X, y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["KNNs\n","A acurácia do modelo \"Stacking\" é 96.66%\n","A acurácia do modelo \"Voting\" é 96.84%\n","\n","DTs\n","A acurácia do modelo \"Ada Boost Decision Tree\" é 91.05%\n","A acurácia do modelo \"Bagging Decision Tree\" é 94.20%\n","A acurácia do modelo \"Ada Boost Decision Tree w/ random split\" é 93.67%\n","A acurácia do modelo \"Bagging Decision Tree w/ random split\" é 96.13%\n","A acurácia do modelo \"Ada Boost Decision Tree w/ max_depth = 3\" é 96.83%\n","A acurácia do modelo \"Bagging Decision Tree w/ max_depth = 3\" é 93.86%\n","A acurácia do modelo \"Extra Trees\" é 96.67%\n","A acurácia do modelo \"Gradient Boosting\" é 96.14%\n","A acurácia do modelo \"Random Forest\" é 96.13%\n","A acurácia do modelo \"Stacking\" é 93.51%\n","A acurácia do modelo \"Voting\" é 92.98%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XqIS0YMFAg4V","colab_type":"text"},"source":["\n","---\n","\n","### Questão 6. \n","\n","Discuta as acurácias obtidas nas Questões 3, 4 e 5. Houve algum ganho ao utilizar Ensembles? Em qual situação houve maior ganho?"]},{"cell_type":"markdown","metadata":{"id":"refqctDJUXrE","colab_type":"text"},"source":["Os exemplos utilizados serão disponilizados para a resposta serão disponibilizados a seguir: \n","\n","# Resultados Questão 3\n","\n","MLPs\n","* A acurácia do modelo \"MLP camada escondida (5, 5)\" é 97.89%\n","* A acurácia do modelo \"MLP camada escondida (100,)\" é 97.37%\n","* A acurácia do modelo \"MLP camada escondida (200,)\" é 97.89%\n","\n","SVMs\n","* A acurácia do modelo \"SVM poly(3)\" é 90.34%\n","* A acurácia do modelo \"SVM linear\" é 97.54%\n","* A acurácia do modelo \"SVM rbf\" é 97.71%\n","\n","# Resultados Questão 4\n","\n","KNNs\n","* A acurácia do modelo \"KNN (K=5)\" é 96.66%\n","* A acurácia do modelo \"KNN (K=2)\" é 94.55%\n","* A acurácia do modelo \"KNN (K=10)\" é 97.01%\n","\n","DTs\n","* A acurácia do modelo \"Decision Tree\" é 92.80%\n","* A acurácia do modelo \"Decision Tree w/ random split\" é 92.97%\n","* A acurácia do modelo \"Decision Tree w/ max_depth = 3\" é 90.70%\n","\n","# Resultados Questão 5\n","\n","KNNs\n","* A acurácia do modelo \"Stacking\" é 96.66%\n","* A acurácia do modelo \"Voting\" é 96.84%\n","\n","DTs\n","* A acurácia do modelo \"Ada Boost Decision Tree\" é 91.05%\n","* A acurácia do modelo \"Bagging Decision Tree\" é 94.20%\n","* A acurácia do modelo \"Ada Boost Decision Tree w/ random split\" é 93.67%\n","* A acurácia do modelo \"Bagging Decision Tree w/ random split\" é 96.13%\n","* A acurácia do modelo \"Ada Boost Decision Tree w/ max_depth = 3\" é 96.83%\n","* A acurácia do modelo \"Bagging Decision Tree w/ max_depth = 3\" é 93.86%\n","* A acurácia do modelo \"Extra Trees\" é 96.67%\n","* A acurácia do modelo \"Gradient Boosting\" é 96.14%\n","* A acurácia do modelo \"Random Forest\" é 96.13%\n","* A acurácia do modelo \"Stacking\" é 93.51%\n","* A acurácia do modelo \"Voting\" é 92.98%\n","\n","\n","# Discussão\n","\n","Ao compararmos as acurácias dos algoritmos de forma independente, e ao utilizarmos o ensemble pudemos notar que o ensemble traz ganhos, dado a comparação das as acuracias dos algotitmos das células acima, como podemos identificar ao compararmos as DT com acurácia de 92% e Ada Boost Decision Tree w/ max_depth com 96%, mas nem todos os casos apresentam melhoras, como o exemplo do Ada Boost Decision Tree onde a acurária cai para 91.05%, é interessante notar que o desempenho do MLP no melhor caso com 97.89% ainda supera a utilização de ensemble nos casos de teste utilizados, isso demonstra que o a escolha dos algoritmo que serão utilizados como estimadores requerem domínio do problema, e da execução dos mesmos, pois como podemos ver neste exemplo (que não dita a regra dos demais, mas levanta a hipótese em discussão) a estratégia que deveria trazer os melhores resultados não o fez, em grupo pensamos em duas teorias que podem responder bem este problema:\n"," \n","Uma delas é a citada sobre o conhecimento dos algoritmos e das combinações realizadas e a outra se refere ao tamanho e complexidade do problema abordado, dado que os algoritmos sem boost já apresentam resultados muito bons acima de 90% de acurácia, sendo assim é dificil obter resultados melhores sem obter um pouco de overfitting sobre o conjunto.\n","\n","Vale ressaltar que utilizamos o random state = 42 para os exemplos, o motivo para tal decisão é garantir a replicabilidade do experimento, pois temos consciência de que o mesmo será corrigido e poderia gerar resultados diferentes. Em contra partida, podemos estar analisando um caso específico onde um dos classificadores tem acurária melhor, por isso levantamos a hipótese anteriormente e não concluímos em dizer que o ensemble não gera ganhos em sua aplicação.\n","\n"]}]}